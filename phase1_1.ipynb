{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9w67mZW1i333",
    "tags": []
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ohy-uGrhk_6j"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ES23zLXhi34A",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5C72evWemRM_"
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "  image_pickle_file_path = 'images.pkl'\n",
    "  label_pickle_file_path = 'label.pkl'\n",
    "\n",
    "  with open(image_pickle_file_path, 'rb') as file:\n",
    "    images = pickle.load(file)\n",
    "\n",
    "  with open(label_pickle_file_path, 'rb') as file:\n",
    "    labels = pickle.load(file)\n",
    "\n",
    "  return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PegQSxmRnEAU"
   },
   "outputs": [],
   "source": [
    "images, labels = load_dataset()\n",
    "labels = np.array(labels)\n",
    "random_indices = np.random.choice(560, size=n_images, replace=False)\n",
    "# Extract the randomly selected values\n",
    "random_values = images[random_indices]\n",
    "random_labels = labels[random_indices]\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Images:\n",
    "    image: np.ndarray = None\n",
    "    original_features = []\n",
    "    features = []\n",
    "    clusters = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4EkzGxIi34C"
   },
   "source": [
    "## Proccess on images\n",
    "- Extract features\n",
    "- normalize features\n",
    "- make features a single dimnetion vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "niz6RZqTi34D"
   },
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    features = []\n",
    "    original_features = []\n",
    "\n",
    "    img_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # For each pixel in the image\n",
    "    for i in range(img_hsv.shape[0]):\n",
    "        for j in range(img_hsv.shape[1]):\n",
    "            pixel = img_hsv[i, j]\n",
    "            h, s, v = pixel\n",
    "            x, y = i, j\n",
    "            \n",
    "            features.append((h, s, v, x, y))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thgfwhB_i34F"
   },
   "outputs": [],
   "source": [
    "def normalize_features(features):\n",
    "    features_array = np.array(features)\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_features_array = scaler.fit_transform(features_array)\n",
    "    normalized_features = normalized_features_array.tolist()\n",
    "    return normalized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4zo_qGUNi34H",
    "outputId": "44412444-40e7-41ab-e547-d11217b7b25f"
   },
   "outputs": [],
   "source": [
    "new_features = []\n",
    "\n",
    "for img in random_values:\n",
    "    features = extract_features(img)\n",
    "    new_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_vQuK0ii34J"
   },
   "outputs": [],
   "source": [
    "# normalize features\n",
    "for i, fimg in enumerate(new_features):\n",
    "    new_features[i] = normalize_features(fimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_priority(arr, color, pos):\n",
    "    color_columns = np.tile(arr[:, :3], (1, color))\n",
    "    pos_columns = np.tile(arr[:, 3:], (1, pos))\n",
    "    duplicated_arr = np.concatenate((color_columns, pos_columns), axis=1)\n",
    "\n",
    "    return duplicated_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_freq = []\n",
    "for nf in new_features:\n",
    "    new_features_freq.append(set_priority(np.array(nf), 4, 2).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4kDj4dsi34K"
   },
   "source": [
    "## clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yxNa4MT9EQ_",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3BrJgCQi34K"
   },
   "outputs": [],
   "source": [
    "k_number = 15\n",
    "kmeans = KMeans(n_clusters=k_number)\n",
    "new_clusters = []\n",
    "for nf in new_features_freq:\n",
    "    clusters = kmeans.fit_predict(nf)\n",
    "    new_clusters.append(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, nc in enumerate(new_clusters):\n",
    "    new_clusters[i] = nc.reshape(random_values.shape[1], random_values.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zi_CypDqi34L"
   },
   "source": [
    "## extracting clusters features for each image sepratedly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_triads(array1, array2):   \n",
    "\n",
    "    unique_values = np.unique(array1)\n",
    "    result = []\n",
    "\n",
    "    for value in unique_values:\n",
    "        indexes = np.where(array1 == value)[0]\n",
    "        triads = array2[indexes, :].tolist()\n",
    "        result.append(triads)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean color for each cluster in each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean(data):\n",
    "\n",
    "    data_array = np.array(data)\n",
    "    mean_values = np.mean(data_array, axis=0)\n",
    "    mean_values = mean_values.astype(int)\n",
    "    mean_values_list = mean_values.tolist()\n",
    "    \n",
    "    return mean_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_clusters_each_image(new_cls, random_values):\n",
    "\n",
    "    all_images_mean_values = []\n",
    "    \n",
    "    for i, image_cls in enumerate(new_cls):\n",
    "\n",
    "        one_image_clusters_mean_values = []\n",
    "        reshaped_image_cls = image_cls.reshape(image_cls.shape[0] * image_cls.shape[1])\n",
    "        reshaped_random_value = random_values[i].reshape(random_values.shape[1] * random_values.shape[2], random_values.shape[3])\n",
    "\n",
    "        similar_clusters_pixels = find_matching_triads(reshaped_image_cls, reshaped_random_value)\n",
    "\n",
    "        for smp in similar_clusters_pixels:\n",
    "            one_image_clusters_mean_values.append(calculate_mean(smp))\n",
    "\n",
    "        all_images_mean_values.append(one_image_clusters_mean_values)\n",
    "\n",
    "    return all_images_mean_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_each_cluster_each_image = mean_clusters_each_image(new_clusters, random_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_clustering(image_clusters, each_cluster_color, image_index):\n",
    "    # Create an empty array to hold the HSV values for each pixel\n",
    "    rgb_image = np.zeros((image_clusters.shape[0], image_clusters.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # Assign the corresponding HSV values to each pixel\n",
    "    for i in range(image_clusters.shape[0]):\n",
    "        for j in range(image_clusters.shape[1]):\n",
    "            value = image_clusters[i, j] \n",
    "            hsv = each_cluster_color[value]\n",
    "            # rgb = colorsys.hsv_to_rgb(hsv[0] / 360, hsv[1] / 100, hsv[2] / 100)\n",
    "            # rgb_image[i, j] = np.round(np.array(rgb) * 255).astype(int)\n",
    "            rgb_image[i, j] = hsv\n",
    "\n",
    "    # Display the image with corresponding RGB values using cv2.imshow\n",
    "    cv2.imshow('org', random_values[image_index])\n",
    "    cv2.imshow('Image with Corresponding RGB Values', cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_cluster_color = [\n",
    "    [255, 0, 0],    # Red\n",
    "    [0, 255, 0],    # Green\n",
    "    [0, 0, 255],    # Blue\n",
    "    [255, 255, 0],  # Yellow\n",
    "    [255, 0, 255],  # Magenta\n",
    "    [0, 255, 255],  # Cyan\n",
    "    [128, 0, 0],    # Maroon\n",
    "    [0, 128, 0],    # Green (Dark)\n",
    "    [0, 0, 128],    # Navy\n",
    "    [128, 128, 128], # Gray\n",
    "    [255, 128, 0],  # Orange\n",
    "    [128, 0, 128],  # Purple\n",
    "    [0, 128, 128],  # Teal\n",
    "    [128, 128, 0],  # Olive\n",
    "    [192, 192, 192]  # Silver\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, img_clusters in enumerate(new_clusters[:2]):\n",
    "#     display_clustering(img_clusters, each_cluster_color, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFn0nBVDi34f"
   },
   "source": [
    "## create clusters feature vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cluster_features(image_number, image_clusters, arr_new_features, k_number):\n",
    "    clusters_features = []\n",
    "    clusters = [[] for i in range(k_number)]\n",
    "    for index, value in enumerate(image_clusters):\n",
    "        clusters[value].append(arr_new_features[image_number, index])\n",
    "    for cluster in clusters: # clusters contains all pixels which belong to the same cluster.\n",
    "        temp_array = np.array(cluster)\n",
    "        min_value = np.min(temp_array, axis=0)\n",
    "        max_value = np.max(temp_array, axis=0)\n",
    "        mean_value = np.mean(temp_array, axis=0)\n",
    "        x_field = max_value[3] - min_value[3]\n",
    "        y_field = max_value[4] - min_value[4]\n",
    "        shape_field = np.array([x_field / y_field])\n",
    "        combined_results = np.concatenate((min_value[:3], max_value[:3], mean_value[:3], shape_field), axis=None)\n",
    "        clusters_features.append(combined_results)\n",
    "\n",
    "    return np.array(clusters_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_clusters_features = []\n",
    "arr_new_features = np.array(new_features)\n",
    "for image_num, image_clusters in enumerate(new_clusters):\n",
    "    reshaped_image_clusters = image_clusters.reshape(image_clusters.shape[0] * image_clusters.shape[1])\n",
    "    all_images_clusters_features.append(extract_cluster_features(image_num, \n",
    "                                                                 reshaped_image_clusters,\n",
    "                                                                 arr_new_features, k_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set priority for clusters features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_pri = 5\n",
    "pos_pri = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_priority_clusters_vectors(arr, color, pos):\n",
    "    color_columns = np.tile(arr[:, :9], (1, color))\n",
    "    pos_columns = np.tile(arr[:, 9:], (1, pos))\n",
    "    duplicated_arr = np.concatenate((color_columns, pos_columns), axis=1)\n",
    "\n",
    "    return duplicated_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_images_clusters_features_freq = []\n",
    "# for nf in all_images_clusters_features:\n",
    "#     all_images_clusters_features_freq.\\\n",
    "#             append(set_priority_clusters_vectors(np.array(nf), color_pri, pos_pri).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_images_clusters_features_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZnhtPpgi34g"
   },
   "source": [
    "## clustering clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_number_2 = 100\n",
    "# kmeans_2 = KMeans(n_clusters=k_number_2)\n",
    "# arr_all_images_clusters_features_freq = np.array(all_images_clusters_features_freq)\n",
    "# arr_all_images_clusters_features_freq = arr_all_images_clusters_features_freq.reshape(\\\n",
    "#                                             arr_all_images_clusters_features_freq.shape[0] *\\\n",
    "#                                             arr_all_images_clusters_features_freq.shape[1],\n",
    "#                                             arr_all_images_clusters_features_freq.shape[2])\n",
    "\n",
    "# clusters2 = kmeans_2.fit_predict(arr_all_images_clusters_features_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters2_arr = clusters2.reshape(np.array(all_images_clusters_features_freq).shape[0], np.array(all_images_clusters_features_freq).shape[1])\n",
    "# clusters2_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_numbers(lst, k_number_2):\n",
    "    # Initialize a list to store counts\n",
    "    count_list = [0] * k_number_2  # Index 0 is not used to align with numbers 1 to 10\n",
    "\n",
    "    # Count occurrences of each number in the list\n",
    "    for num in lst:\n",
    "        if 1 <= num <= 10:\n",
    "            count_list[num - 1] += 1  # Adjust index to align with numbers 1 to 10\n",
    "\n",
    "    return count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram = np.empty((n_images, k_number_2))\n",
    "# for i, img_cls in enumerate(clusters2_arr):\n",
    "#     histogram[i] = count_numbers(img_cls, k_number_2)\n",
    "\n",
    "# histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Classify the datapoints with the Random Forest Classifier\n",
    "def classify(datapoints, labels):\n",
    "  test_size = 0.2\n",
    "  X_train, X_test, y_train, y_test = train_test_split(datapoints, labels, test_size=test_size, random_state=42)\n",
    "\n",
    "  clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "  clf.fit(X_train, y_train)\n",
    "\n",
    "  y_pred = clf.predict(X_test)\n",
    "\n",
    "  y_prob_test = clf.predict_proba(X_test)\n",
    "  y_prob_train = clf.predict_proba(X_train)\n",
    "  y_prob = np.concatenate((y_prob_test, y_prob_train), axis=0)\n",
    "\n",
    "  true_lables = np.concatenate((y_test, y_train))\n",
    "\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  # print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "  # Print the true labels and predicted labels\n",
    "  # print(\"True labels:\")\n",
    "  # print(y_test)\n",
    "\n",
    "  # print(\"Predicted labels:\")\n",
    "  # print(y_pred)\n",
    "\n",
    "  # print(\"Probability estimates:\")\n",
    "  # print(y_prob)\n",
    "\n",
    "  return [accuracy, true_lables, y_pred, y_prob]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create images feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create images feature vectors without removing clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Extract a features for each image \n",
    "    by calculating the mean of all its culsters\n",
    "\"\"\"\n",
    "def calculate_mean_imgs_clstrs_features():\n",
    "    histograms = []\n",
    "    for ftr_clstrs_img in all_images_clusters_features:\n",
    "        histograms.append(np.mean(ftr_clstrs_img, axis=0))\n",
    "    return histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms = calculate_mean_imgs_clstrs_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create images feature vectors with removing clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_clusters_features_bak = all_images_clusters_features\n",
    "k_number_bak = k_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_back_ups():\n",
    "    all_images_clusters_features_bak = all_images_clusters_features\n",
    "    k_number_bak = k_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Extract a features for each image \n",
    "    by calculating the mean of its culsters excpet one of them\n",
    "\"\"\"\n",
    "def calculate_mean_imgs_clstrs_except_index(index_, img_num, remove):\n",
    "    histograms = []\n",
    "    for i, ftr_clstrs_img in enumerate(all_images_clusters_features_bak):\n",
    "        if i == img_num and remove:\n",
    "            histograms.append(np.mean(np.concatenate((ftr_clstrs_img[:index_], ftr_clstrs_img[index_+1:])), axis=0))\n",
    "        else:\n",
    "            histograms.append(np.mean(ftr_clstrs_img, axis=0))  \n",
    "\n",
    "    return histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifies images while a cluster of an image has been removed.\n",
    "# This happens for all clusters of that image.\n",
    "def cal_classify_results(img_num, remove):\n",
    "    classify_results = []\n",
    "    for clstr_num in range(k_number_bak):\n",
    "        histograms = calculate_mean_imgs_clstrs_except_index(index_= clstr_num, img_num = img_num, remove=remove)\n",
    "        rslt = classify(histograms, random_labels)\n",
    "        classify_results.append(rslt)\n",
    "    return classify_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify_results = cal_classify_results(1, remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gather the labels probability of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_probs(classify_results):\n",
    "    probs = [ [] for _ in range(len(classify_results[0][3])) ]\n",
    "    for result in classify_results:\n",
    "        for i, imgs_probs in enumerate(result[3]):\n",
    "            probs[i].append(imgs_probs)\n",
    "    \n",
    "    return(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs = cal_probs(classify_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the lables probability of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_probs(probs, classify_results):\n",
    "    for i, prob in enumerate(probs):\n",
    "        print(np.array(prob))\n",
    "        print(f\"acc={classify_results[i][0]}, true labels={classify_results[i][1]}, predicted labels={classify_results[i][2]}\")\n",
    "        print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_probs(probs, classify_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## determine clusters importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_images_clusters_importance = [{} for _ in range(n_images)]\n",
    "\n",
    "for d in default_images_clusters_importance:\n",
    "    for i in range(15):\n",
    "        d[i] = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    prob for each image and true label would be checked,\n",
    "    ckeck in which one of those 15 state has best result for true label\n",
    "\n",
    "'''\n",
    "def check_clusters_importance(default_images_clusters_importance):\n",
    "    images_clusters_importance = default_images_clusters_importance\n",
    "    # for each image in test\n",
    "    for img in range(n_images): \n",
    "        \n",
    "        Effect_of_cluster_removal = images_clusters_importance[img]\n",
    "        clusters = list(Effect_of_cluster_removal.keys())\n",
    "\n",
    "        classify_results = cal_classify_results(img, remove=False)\n",
    "        classify_results_remove = cal_classify_results(img, remove=True)\n",
    "        \n",
    "        probs = cal_probs(classify_results)\n",
    "        probs_remove = cal_probs(classify_results_remove)\n",
    "        \n",
    "        # print(classify_results[0][4])\n",
    "        true_label = classify_results[0][1][img]\n",
    "        # print(true_label)\n",
    "        # print(classify_results)\n",
    "        class_probability = probs[img][0][true_label]\n",
    "        # print(probs)\n",
    "        # print(class_probability)\n",
    "        # check the effect of cluster removal\n",
    "        # for each cluster\n",
    "        for i, cls in enumerate(clusters):\n",
    "            class_probability_after_remove = probs_remove[img][i][true_label]\n",
    "            Effect_of_cluster_removal[cls] = class_probability_after_remove - class_probability\n",
    "\n",
    "        # this dictionary contains the importance of\n",
    "        # clusters for an image in ascending order.\n",
    "        # (first element has the least importance)\n",
    "        importance_of_clusters = dict(sorted(Effect_of_cluster_removal.items(), key=lambda item: item[1]))\n",
    "        images_clusters_importance.append(importance_of_clusters)\n",
    "    \n",
    "    return images_clusters_importance\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove least important cluster from each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_least_important_clusters(images_clusters_importance):\n",
    "    modified_all_images_clusters_features = []\n",
    "    for i, img_clstr in enumerate(images_clusters_importance):\n",
    "        keys_list = list(img_clstr.keys())\n",
    "        least_important_clstr = keys_list[0]\n",
    "        modified_all_images_clusters_features.append(np.delete(all_images_clusters_features_bak[i], least_important_clstr, axis=0))\n",
    "    \n",
    "    return modified_all_images_clusters_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_clusters_importance = check_clusters_importance()\n",
    "# images_clusters_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_images_clusters_features_bak = remove_least_important_clusters(images_clusters_importance)\n",
    "# k_number_bak -= 1\n",
    "# all_images_clusters_features_bak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove clusters based on importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_back_ups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(k_number - 1):\n",
    "    print(i, \"----------------------------------------------------\")\n",
    "    images_clusters_importance = check_clusters_importance(default_images_clusters_importance)\n",
    "    default_images_clusters_importance = images_clusters_importance\n",
    "    print(np.array(images_clusters_importance[0]))\n",
    "    all_images_clusters_features_bak = remove_least_important_clusters(images_clusters_importance)\n",
    "    print(np.array(all_images_clusters_features_bak[0]))\n",
    "    k_number_bak -= 1\n",
    "    print(\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_clusters_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def display_selected_clusters(image_clusters, each_cluster_color, selected_clusters, image_index):\n",
    "    # Create an empty array to hold the HSV values for each pixel\n",
    "    rgb_image = np.zeros((image_clusters.shape[0], image_clusters.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # Assign the corresponding HSV values to each pixel for the selected clusters\n",
    "    for i in range(image_clusters.shape[0]):\n",
    "        for j in range(image_clusters.shape[1]):\n",
    "            value = image_clusters[i, j]\n",
    "            if value in selected_clusters:\n",
    "                hsv = each_cluster_color[value]\n",
    "                rgb_image[i, j] = hsv\n",
    "\n",
    "    # Display the image with corresponding RGB values using cv2.imshow\n",
    "    cv2.imshow('org', random_values[image_index])\n",
    "    cv2.imshow('Image with Selected Clusters', cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_clusters = [5]  # Specify the clusters you want to display\n",
    "display_selected_clusters(new_clusters[1], each_cluster_color, selected_clusters, 1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "3mVvdAtI9ONL",
    "lBEBJMkk9Tsz",
    "UcQ9WDY59Zlb",
    "06xiqibEqHid",
    "aWfpqHU1qPh4"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
