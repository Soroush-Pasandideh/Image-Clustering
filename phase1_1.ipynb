{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9w67mZW1i333",
    "tags": []
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Ohy-uGrhk_6j"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ES23zLXhi34A",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "5C72evWemRM_"
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "  image_pickle_file_path = 'images.pkl'\n",
    "  label_pickle_file_path = 'label.pkl'\n",
    "\n",
    "  with open(image_pickle_file_path, 'rb') as file:\n",
    "    images = pickle.load(file)\n",
    "\n",
    "  with open(label_pickle_file_path, 'rb') as file:\n",
    "    labels = pickle.load(file)\n",
    "\n",
    "  return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "PegQSxmRnEAU"
   },
   "outputs": [],
   "source": [
    "images, labels = load_dataset()\n",
    "labels = np.array(labels)\n",
    "random_indices = np.random.choice(560, size=n_images, replace=False)\n",
    "# Extract the randomly selected values\n",
    "random_values = images[random_indices]\n",
    "random_labels = labels[random_indices]\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Images:\n",
    "    image: np.ndarray = None\n",
    "    original_features = []\n",
    "    features = []\n",
    "    clusters = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4EkzGxIi34C"
   },
   "source": [
    "## Proccess on images\n",
    "- Extract features\n",
    "- normalize features\n",
    "- make features a single dimnetion vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "niz6RZqTi34D"
   },
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    features = []\n",
    "    original_features = []\n",
    "\n",
    "    img_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # For each pixel in the image\n",
    "    for i in range(img_hsv.shape[0]):\n",
    "        for j in range(img_hsv.shape[1]):\n",
    "            pixel = img_hsv[i, j]\n",
    "            h, s, v = pixel\n",
    "            x, y = i, j\n",
    "            \n",
    "            features.append((h, s, v, x, y))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "thgfwhB_i34F"
   },
   "outputs": [],
   "source": [
    "def normalize_features(features):\n",
    "    features_array = np.array(features)\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_features_array = scaler.fit_transform(features_array)\n",
    "    normalized_features = normalized_features_array.tolist()\n",
    "    return normalized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4zo_qGUNi34H",
    "outputId": "44412444-40e7-41ab-e547-d11217b7b25f"
   },
   "outputs": [],
   "source": [
    "new_features = []\n",
    "\n",
    "for img in random_values:\n",
    "    features = extract_features(img)\n",
    "    new_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "D_vQuK0ii34J"
   },
   "outputs": [],
   "source": [
    "# normalize features\n",
    "for i, fimg in enumerate(new_features):\n",
    "    new_features[i] = normalize_features(fimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_priority(arr, color, pos):\n",
    "    color_columns = np.tile(arr[:, :3], (1, color))\n",
    "    pos_columns = np.tile(arr[:, 3:], (1, pos))\n",
    "    duplicated_arr = np.concatenate((color_columns, pos_columns), axis=1)\n",
    "\n",
    "    return duplicated_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_freq = []\n",
    "for nf in new_features:\n",
    "    new_features_freq.append(set_priority(np.array(nf), 4, 2).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4kDj4dsi34K"
   },
   "source": [
    "## clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yxNa4MT9EQ_",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "g3BrJgCQi34K"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "k_number = 15\n",
    "kmeans = KMeans(n_clusters=k_number)\n",
    "new_clusters = []\n",
    "for nf in new_features_freq:\n",
    "    clusters = kmeans.fit_predict(nf)\n",
    "    new_clusters.append(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, nc in enumerate(new_clusters):\n",
    "    new_clusters[i] = nc.reshape(random_values.shape[1], random_values.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zi_CypDqi34L"
   },
   "source": [
    "## extracting clusters features for each image sepratedly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_triads(array1, array2):   \n",
    "\n",
    "    unique_values = np.unique(array1)\n",
    "    result = []\n",
    "\n",
    "    for value in unique_values:\n",
    "        indexes = np.where(array1 == value)[0]\n",
    "        triads = array2[indexes, :].tolist()\n",
    "        result.append(triads)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean color for each cluster in each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean(data):\n",
    "\n",
    "    data_array = np.array(data)\n",
    "    mean_values = np.mean(data_array, axis=0)\n",
    "    mean_values = mean_values.astype(int)\n",
    "    mean_values_list = mean_values.tolist()\n",
    "    \n",
    "    return mean_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_clusters_each_image(new_cls, random_values):\n",
    "\n",
    "    all_images_mean_values = []\n",
    "    \n",
    "    for i, image_cls in enumerate(new_cls):\n",
    "\n",
    "        one_image_clusters_mean_values = []\n",
    "        reshaped_image_cls = image_cls.reshape(image_cls.shape[0] * image_cls.shape[1])\n",
    "        reshaped_random_value = random_values[i].reshape(random_values.shape[1] * random_values.shape[2], random_values.shape[3])\n",
    "\n",
    "        similar_clusters_pixels = find_matching_triads(reshaped_image_cls, reshaped_random_value)\n",
    "\n",
    "        for smp in similar_clusters_pixels:\n",
    "            one_image_clusters_mean_values.append(calculate_mean(smp))\n",
    "\n",
    "        all_images_mean_values.append(one_image_clusters_mean_values)\n",
    "\n",
    "    return all_images_mean_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_each_cluster_each_image = mean_clusters_each_image(new_clusters, random_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_clustering(image_clusters, each_cluster_color, image_index):\n",
    "    # Create an empty array to hold the HSV values for each pixel\n",
    "    rgb_image = np.zeros((image_clusters.shape[0], image_clusters.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # Assign the corresponding HSV values to each pixel\n",
    "    for i in range(image_clusters.shape[0]):\n",
    "        for j in range(image_clusters.shape[1]):\n",
    "            value = image_clusters[i, j] \n",
    "            hsv = each_cluster_color[value]\n",
    "            # rgb = colorsys.hsv_to_rgb(hsv[0] / 360, hsv[1] / 100, hsv[2] / 100)\n",
    "            # rgb_image[i, j] = np.round(np.array(rgb) * 255).astype(int)\n",
    "            rgb_image[i, j] = hsv\n",
    "\n",
    "    # Display the image with corresponding RGB values using cv2.imshow\n",
    "    cv2.imshow('org', random_values[image_index])\n",
    "    cv2.imshow('Image with Corresponding RGB Values', cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_cluster_color = [\n",
    "    [255, 0, 0],    # Red\n",
    "    [0, 255, 0],    # Green\n",
    "    [0, 0, 255],    # Blue\n",
    "    [255, 255, 0],  # Yellow\n",
    "    [255, 0, 255],  # Magenta\n",
    "    [0, 255, 255],  # Cyan\n",
    "    [128, 0, 0],    # Maroon\n",
    "    [0, 128, 0],    # Green (Dark)\n",
    "    [0, 0, 128],    # Navy\n",
    "    [128, 128, 128], # Gray\n",
    "    [255, 128, 0],  # Orange\n",
    "    [128, 0, 128],  # Purple\n",
    "    [0, 128, 128],  # Teal\n",
    "    [128, 128, 0],  # Olive\n",
    "    [192, 192, 192]  # Silver\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, img_clusters in enumerate(new_clusters[:2]):\n",
    "#     display_clustering(img_clusters, each_cluster_color, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFn0nBVDi34f"
   },
   "source": [
    "## create clusters feature vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cluster_features(image_number, image_clusters, arr_new_features, k_number):\n",
    "    clusters_features = []\n",
    "    clusters = [[] for i in range(k_number)]\n",
    "    for index, value in enumerate(image_clusters):\n",
    "        clusters[value].append(arr_new_features[image_number, index])\n",
    "    for cluster in clusters: # clusters contains all pixels which belong to the same cluster.\n",
    "        temp_array = np.array(cluster)\n",
    "        min_value = np.min(temp_array, axis=0)\n",
    "        max_value = np.max(temp_array, axis=0)\n",
    "        mean_value = np.mean(temp_array, axis=0)\n",
    "        x_field = max_value[3] - min_value[3]\n",
    "        y_field = max_value[4] - min_value[4]\n",
    "        shape_field = np.array([x_field / y_field])\n",
    "        combined_results = np.concatenate((min_value[:3], max_value[:3], mean_value[:3], shape_field), axis=None)\n",
    "        clusters_features.append(combined_results)\n",
    "\n",
    "    return np.array(clusters_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_clusters_features = []\n",
    "arr_new_features = np.array(new_features)\n",
    "for image_num, image_clusters in enumerate(new_clusters):\n",
    "    reshaped_image_clusters = image_clusters.reshape(image_clusters.shape[0] * image_clusters.shape[1])\n",
    "    all_images_clusters_features.append(extract_cluster_features(image_num, \n",
    "                                                                 reshaped_image_clusters,\n",
    "                                                                 arr_new_features, k_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set priority for clusters features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_pri = 5\n",
    "pos_pri = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_priority_clusters_vectors(arr, color, pos):\n",
    "    color_columns = np.tile(arr[:, :9], (1, color))\n",
    "    pos_columns = np.tile(arr[:, 9:], (1, pos))\n",
    "    duplicated_arr = np.concatenate((color_columns, pos_columns), axis=1)\n",
    "\n",
    "    return duplicated_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_images_clusters_features_freq = []\n",
    "# for nf in all_images_clusters_features:\n",
    "#     all_images_clusters_features_freq.\\\n",
    "#             append(set_priority_clusters_vectors(np.array(nf), color_pri, pos_pri).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_images_clusters_features_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZnhtPpgi34g"
   },
   "source": [
    "## clustering clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_number_2 = 100\n",
    "# kmeans_2 = KMeans(n_clusters=k_number_2)\n",
    "# arr_all_images_clusters_features_freq = np.array(all_images_clusters_features_freq)\n",
    "# arr_all_images_clusters_features_freq = arr_all_images_clusters_features_freq.reshape(\\\n",
    "#                                             arr_all_images_clusters_features_freq.shape[0] *\\\n",
    "#                                             arr_all_images_clusters_features_freq.shape[1],\n",
    "#                                             arr_all_images_clusters_features_freq.shape[2])\n",
    "\n",
    "# clusters2 = kmeans_2.fit_predict(arr_all_images_clusters_features_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters2_arr = clusters2.reshape(np.array(all_images_clusters_features_freq).shape[0], np.array(all_images_clusters_features_freq).shape[1])\n",
    "# clusters2_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_numbers(lst, k_number_2):\n",
    "    # Initialize a list to store counts\n",
    "    count_list = [0] * k_number_2  # Index 0 is not used to align with numbers 1 to 10\n",
    "\n",
    "    # Count occurrences of each number in the list\n",
    "    for num in lst:\n",
    "        if 1 <= num <= 10:\n",
    "            count_list[num - 1] += 1  # Adjust index to align with numbers 1 to 10\n",
    "\n",
    "    return count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram = np.empty((n_images, k_number_2))\n",
    "# for i, img_cls in enumerate(clusters2_arr):\n",
    "#     histogram[i] = count_numbers(img_cls, k_number_2)\n",
    "\n",
    "# histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Classify the datapoints with the Random Forest Classifier\n",
    "def classify(datapoints, labels):\n",
    "  test_size = 0.2\n",
    "  X_train, X_test, y_train, y_test = train_test_split(datapoints, labels, test_size=test_size, random_state=42)\n",
    "\n",
    "  clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "  clf.fit(X_train, y_train)\n",
    "\n",
    "  y_pred = clf.predict(X_test)\n",
    "\n",
    "  y_prob_test = clf.predict_proba(X_test)\n",
    "  y_prob_train = clf.predict_proba(X_train)\n",
    "  y_prob = np.concatenate((y_prob_test, y_prob_train), axis=0)\n",
    "\n",
    "  true_lables = np.concatenate((y_test, y_train))\n",
    "\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  # print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "  # Print the true labels and predicted labels\n",
    "  # print(\"True labels:\")\n",
    "  # print(y_test)\n",
    "\n",
    "  # print(\"Predicted labels:\")\n",
    "  # print(y_pred)\n",
    "\n",
    "  # print(\"Probability estimates:\")\n",
    "  # print(y_prob)\n",
    "\n",
    "  return [accuracy, true_lables, y_pred, y_prob, y_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create images feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create images feature vectors without removing clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Extract a features for each image \n",
    "    by calculating the mean of all its culsters\n",
    "\"\"\"\n",
    "def calculate_mean_imgs_clstrs_features():\n",
    "    histograms = []\n",
    "    for ftr_clstrs_img in all_images_clusters_features:\n",
    "        histograms.append(np.mean(ftr_clstrs_img, axis=0))\n",
    "    return histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms = calculate_mean_imgs_clstrs_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create images feature vectors with removing clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_clusters_features_bak = all_images_clusters_features\n",
    "k_number_bak = k_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_back_ups():\n",
    "    all_images_clusters_features_bak = all_images_clusters_features\n",
    "    k_number_bak = k_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Extract a features for each image \n",
    "    by calculating the mean of its culsters excpet one of them\n",
    "\"\"\"\n",
    "def calculate_mean_imgs_clstrs_except_index(index_, img_num, remove):\n",
    "    histograms = []\n",
    "    for i, ftr_clstrs_img in enumerate(all_images_clusters_features_bak):\n",
    "        if i == img_num and remove:\n",
    "            histograms.append(np.mean(np.concatenate((ftr_clstrs_img[:index_], ftr_clstrs_img[index_+1:])), axis=0))\n",
    "        else:\n",
    "            histograms.append(np.mean(ftr_clstrs_img, axis=0))  \n",
    "\n",
    "    return histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifies images while a cluster of an image has been removed.\n",
    "# This happens for all clusters of that image.\n",
    "def cal_classify_results(img_num, remove):\n",
    "    classify_results = []\n",
    "    for clstr_num in range(k_number_bak):\n",
    "        histograms = calculate_mean_imgs_clstrs_except_index(index_= clstr_num, img_num = img_num, remove=remove)\n",
    "        rslt = classify(histograms, random_labels)\n",
    "        classify_results.append(rslt)\n",
    "    return classify_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify_results = cal_classify_results(1, remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gather the labels probability of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_probs(classify_results):\n",
    "    probs = [ [] for _ in range(len(classify_results[0][3])) ]\n",
    "    for result in classify_results:\n",
    "        for i, imgs_probs in enumerate(result[3]):\n",
    "            probs[i].append(imgs_probs)\n",
    "    \n",
    "    return(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs = cal_probs(classify_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the lables probability of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_probs(probs, classify_results):\n",
    "    for i, prob in enumerate(probs):\n",
    "        print(np.array(prob))\n",
    "        print(f\"acc={classify_results[i][0]}, true labels={classify_results[i][1]}, predicted labels={classify_results[i][2]}\")\n",
    "        print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_probs(probs, classify_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## determine clusters importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    prob for each image and true label would be checked,\n",
    "    ckeck in which one of those 15 state has best result for true label\n",
    "    \n",
    "'''\n",
    "I_KNOW = n_images\n",
    "def check_clusters_importance():\n",
    "    images_clusters_importance = []\n",
    "    # for each image in test\n",
    "    for img in range(I_KNOW): \n",
    "        \n",
    "        Effect_of_cluster_removal = {}\n",
    "\n",
    "        classify_results = cal_classify_results(img, remove=False)\n",
    "        classify_results_remove = cal_classify_results(img, remove=True)\n",
    "        \n",
    "        probs = cal_probs(classify_results)\n",
    "        probs_remove = cal_probs(classify_results_remove)\n",
    "        \n",
    "        # print(classify_results[0][4])\n",
    "        true_label = classify_results[0][1][img]\n",
    "        # print(true_label)\n",
    "        # print(classify_results)\n",
    "        class_probability = probs[img][0][true_label]\n",
    "        # print(probs)\n",
    "        # print(class_probability)\n",
    "        # check the effect of cluster removal\n",
    "        # for each cluster\n",
    "        for i in range(len(probs_remove[img])):\n",
    "            class_probability_after_remove = probs_remove[img][i][true_label]\n",
    "            Effect_of_cluster_removal[i] = class_probability_after_remove - class_probability\n",
    "\n",
    "        # this dictionary contains the importance of\n",
    "        # clusters for an image in ascending order.\n",
    "        # (first element has the least importance)\n",
    "        importance_of_clusters = dict(sorted(Effect_of_cluster_removal.items(), key=lambda item: item[1]))\n",
    "        images_clusters_importance.append(importance_of_clusters)\n",
    "    \n",
    "    return images_clusters_importance\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove least important cluster from each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_least_important_clusters(images_clusters_importance):\n",
    "    modified_all_images_clusters_features = []\n",
    "    for i, img_clstr in enumerate(images_clusters_importance):\n",
    "        keys_list = list(img_clstr.keys())\n",
    "        least_important_clstr = keys_list[0]\n",
    "        modified_all_images_clusters_features.append(np.delete(all_images_clusters_features_bak[i], least_important_clstr, axis=0))\n",
    "    \n",
    "    return modified_all_images_clusters_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_clusters_importance = check_clusters_importance()\n",
    "# images_clusters_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_images_clusters_features_bak = remove_least_important_clusters(images_clusters_importance)\n",
    "# k_number_bak -= 1\n",
    "# all_images_clusters_features_bak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove clusters based on importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_back_ups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ----------------------------------------------------\n",
      "{5: -0.010000000000000009, 12: -0.010000000000000009, 0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 13: 0.0, 14: 0.0}\n",
      "[[0.         0.55686275 0.00784314 0.51955307 1.         0.55294118\n",
      "  0.18163988 0.88327507 0.25056771 1.75352113]\n",
      " [0.         0.33333333 0.36862745 0.21787709 0.84705882 1.\n",
      "  0.11543231 0.60380325 0.84889362 1.14441417]\n",
      " [0.         0.0745098  0.1254902  0.41340782 0.89019608 1.\n",
      "  0.22766486 0.53297382 0.52419716 0.83072917]\n",
      " [0.         0.         0.43137255 0.99441341 0.66666667 1.\n",
      "  0.17223244 0.2706793  0.85630162 0.79620853]\n",
      " [0.         0.49411765 0.02745098 0.24581006 1.         0.74901961\n",
      "  0.05883126 0.92030251 0.55765122 0.67561521]\n",
      " [0.5027933  0.02745098 0.00392157 1.         1.         0.76862745\n",
      "  0.86589025 0.72584441 0.12050064 1.16627635]\n",
      " [0.         0.03529412 0.20784314 0.78212291 0.90980392 0.90980392\n",
      "  0.19654402 0.57874477 0.53708531 1.14539007]\n",
      " [0.         0.54117647 0.00392157 0.54748603 1.         0.56470588\n",
      "  0.20872404 0.88603746 0.2724855  0.98373984]\n",
      " [0.         0.         0.         0.67039106 0.8        0.48627451\n",
      "  0.13841418 0.49617284 0.17174935 1.00809717]\n",
      " [0.         0.24705882 0.2        0.32960894 0.90196078 0.92156863\n",
      "  0.20893742 0.60679403 0.55770669 0.98353909]\n",
      " [0.         0.50196078 0.00392157 0.57541899 1.         0.63529412\n",
      "  0.24966388 0.8795089  0.23825474 0.60548523]\n",
      " [0.00558659 0.54117647 0.63137255 0.2122905  1.         1.\n",
      "  0.08390306 0.90928913 0.86337658 0.49107143]\n",
      " [0.         0.51372549 0.19607843 0.27374302 1.         0.82745098\n",
      "  0.1209069  0.80235789 0.49041033 0.96173469]\n",
      " [0.         0.         0.25490196 1.         0.45490196 1.\n",
      "  0.17391972 0.19154903 0.93392209 0.56144068]]\n",
      "-------------------------------------------------------\n",
      "1 ----------------------------------------------------\n",
      "{1: -0.02, 6: -0.02, 9: -0.02, 13: -0.02, 2: -0.010000000000000002, 3: -0.010000000000000002, 8: -0.010000000000000002, 0: 0.0, 4: 0.0, 5: 0.0, 7: 0.0, 10: 0.0, 11: 0.0, 12: 0.0}\n",
      "[[0.         0.55686275 0.00784314 0.51955307 1.         0.55294118\n",
      "  0.18163988 0.88327507 0.25056771 1.75352113]\n",
      " [0.         0.0745098  0.1254902  0.41340782 0.89019608 1.\n",
      "  0.22766486 0.53297382 0.52419716 0.83072917]\n",
      " [0.         0.         0.43137255 0.99441341 0.66666667 1.\n",
      "  0.17223244 0.2706793  0.85630162 0.79620853]\n",
      " [0.         0.49411765 0.02745098 0.24581006 1.         0.74901961\n",
      "  0.05883126 0.92030251 0.55765122 0.67561521]\n",
      " [0.5027933  0.02745098 0.00392157 1.         1.         0.76862745\n",
      "  0.86589025 0.72584441 0.12050064 1.16627635]\n",
      " [0.         0.03529412 0.20784314 0.78212291 0.90980392 0.90980392\n",
      "  0.19654402 0.57874477 0.53708531 1.14539007]\n",
      " [0.         0.54117647 0.00392157 0.54748603 1.         0.56470588\n",
      "  0.20872404 0.88603746 0.2724855  0.98373984]\n",
      " [0.         0.         0.         0.67039106 0.8        0.48627451\n",
      "  0.13841418 0.49617284 0.17174935 1.00809717]\n",
      " [0.         0.24705882 0.2        0.32960894 0.90196078 0.92156863\n",
      "  0.20893742 0.60679403 0.55770669 0.98353909]\n",
      " [0.         0.50196078 0.00392157 0.57541899 1.         0.63529412\n",
      "  0.24966388 0.8795089  0.23825474 0.60548523]\n",
      " [0.00558659 0.54117647 0.63137255 0.2122905  1.         1.\n",
      "  0.08390306 0.90928913 0.86337658 0.49107143]\n",
      " [0.         0.51372549 0.19607843 0.27374302 1.         0.82745098\n",
      "  0.1209069  0.80235789 0.49041033 0.96173469]\n",
      " [0.         0.         0.25490196 1.         0.45490196 1.\n",
      "  0.17391972 0.19154903 0.93392209 0.56144068]]\n",
      "-------------------------------------------------------\n",
      "2 ----------------------------------------------------\n",
      "{0: -0.03, 3: -0.03, 10: -0.03, 7: -0.019999999999999997, 11: -0.019999999999999997, 2: -0.009999999999999995, 6: -0.009999999999999995, 9: -0.009999999999999995, 12: -0.009999999999999995, 1: 0.0, 4: 0.0, 5: 0.0, 8: 0.0}\n",
      "[[0.         0.0745098  0.1254902  0.41340782 0.89019608 1.\n",
      "  0.22766486 0.53297382 0.52419716 0.83072917]\n",
      " [0.         0.         0.43137255 0.99441341 0.66666667 1.\n",
      "  0.17223244 0.2706793  0.85630162 0.79620853]\n",
      " [0.         0.49411765 0.02745098 0.24581006 1.         0.74901961\n",
      "  0.05883126 0.92030251 0.55765122 0.67561521]\n",
      " [0.5027933  0.02745098 0.00392157 1.         1.         0.76862745\n",
      "  0.86589025 0.72584441 0.12050064 1.16627635]\n",
      " [0.         0.03529412 0.20784314 0.78212291 0.90980392 0.90980392\n",
      "  0.19654402 0.57874477 0.53708531 1.14539007]\n",
      " [0.         0.54117647 0.00392157 0.54748603 1.         0.56470588\n",
      "  0.20872404 0.88603746 0.2724855  0.98373984]\n",
      " [0.         0.         0.         0.67039106 0.8        0.48627451\n",
      "  0.13841418 0.49617284 0.17174935 1.00809717]\n",
      " [0.         0.24705882 0.2        0.32960894 0.90196078 0.92156863\n",
      "  0.20893742 0.60679403 0.55770669 0.98353909]\n",
      " [0.         0.50196078 0.00392157 0.57541899 1.         0.63529412\n",
      "  0.24966388 0.8795089  0.23825474 0.60548523]\n",
      " [0.00558659 0.54117647 0.63137255 0.2122905  1.         1.\n",
      "  0.08390306 0.90928913 0.86337658 0.49107143]\n",
      " [0.         0.51372549 0.19607843 0.27374302 1.         0.82745098\n",
      "  0.1209069  0.80235789 0.49041033 0.96173469]\n",
      " [0.         0.         0.25490196 1.         0.45490196 1.\n",
      "  0.17391972 0.19154903 0.93392209 0.56144068]]\n",
      "-------------------------------------------------------\n",
      "3 ----------------------------------------------------\n",
      "{7: -0.01, 0: 0.0, 1: 0.0, 4: 0.0, 6: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 2: 0.01, 5: 0.01, 8: 0.01, 3: 0.03}\n",
      "[[0.         0.0745098  0.1254902  0.41340782 0.89019608 1.\n",
      "  0.22766486 0.53297382 0.52419716 0.83072917]\n",
      " [0.         0.         0.43137255 0.99441341 0.66666667 1.\n",
      "  0.17223244 0.2706793  0.85630162 0.79620853]\n",
      " [0.         0.49411765 0.02745098 0.24581006 1.         0.74901961\n",
      "  0.05883126 0.92030251 0.55765122 0.67561521]\n",
      " [0.5027933  0.02745098 0.00392157 1.         1.         0.76862745\n",
      "  0.86589025 0.72584441 0.12050064 1.16627635]\n",
      " [0.         0.03529412 0.20784314 0.78212291 0.90980392 0.90980392\n",
      "  0.19654402 0.57874477 0.53708531 1.14539007]\n",
      " [0.         0.54117647 0.00392157 0.54748603 1.         0.56470588\n",
      "  0.20872404 0.88603746 0.2724855  0.98373984]\n",
      " [0.         0.         0.         0.67039106 0.8        0.48627451\n",
      "  0.13841418 0.49617284 0.17174935 1.00809717]\n",
      " [0.         0.50196078 0.00392157 0.57541899 1.         0.63529412\n",
      "  0.24966388 0.8795089  0.23825474 0.60548523]\n",
      " [0.00558659 0.54117647 0.63137255 0.2122905  1.         1.\n",
      "  0.08390306 0.90928913 0.86337658 0.49107143]\n",
      " [0.         0.51372549 0.19607843 0.27374302 1.         0.82745098\n",
      "  0.1209069  0.80235789 0.49041033 0.96173469]\n",
      " [0.         0.         0.25490196 1.         0.45490196 1.\n",
      "  0.17391972 0.19154903 0.93392209 0.56144068]]\n",
      "-------------------------------------------------------\n",
      "4 ----------------------------------------------------\n",
      "{8: -0.01999999999999999, 2: -0.010000000000000009, 4: -0.010000000000000009, 9: -0.010000000000000009, 0: 0.0, 1: 0.0, 10: 0.0, 3: 0.010000000000000009, 5: 0.010000000000000009, 6: 0.010000000000000009, 7: 0.01999999999999999}\n",
      "[[0.         0.0745098  0.1254902  0.41340782 0.89019608 1.\n",
      "  0.22766486 0.53297382 0.52419716 0.83072917]\n",
      " [0.         0.         0.43137255 0.99441341 0.66666667 1.\n",
      "  0.17223244 0.2706793  0.85630162 0.79620853]\n",
      " [0.         0.49411765 0.02745098 0.24581006 1.         0.74901961\n",
      "  0.05883126 0.92030251 0.55765122 0.67561521]\n",
      " [0.5027933  0.02745098 0.00392157 1.         1.         0.76862745\n",
      "  0.86589025 0.72584441 0.12050064 1.16627635]\n",
      " [0.         0.03529412 0.20784314 0.78212291 0.90980392 0.90980392\n",
      "  0.19654402 0.57874477 0.53708531 1.14539007]\n",
      " [0.         0.54117647 0.00392157 0.54748603 1.         0.56470588\n",
      "  0.20872404 0.88603746 0.2724855  0.98373984]\n",
      " [0.         0.         0.         0.67039106 0.8        0.48627451\n",
      "  0.13841418 0.49617284 0.17174935 1.00809717]\n",
      " [0.         0.50196078 0.00392157 0.57541899 1.         0.63529412\n",
      "  0.24966388 0.8795089  0.23825474 0.60548523]\n",
      " [0.         0.51372549 0.19607843 0.27374302 1.         0.82745098\n",
      "  0.1209069  0.80235789 0.49041033 0.96173469]\n",
      " [0.         0.         0.25490196 1.         0.45490196 1.\n",
      "  0.17391972 0.19154903 0.93392209 0.56144068]]\n",
      "-------------------------------------------------------\n",
      "5 ----------------------------------------------------\n",
      "{1: -0.03, 0: -0.010000000000000009, 2: -0.010000000000000009, 3: -0.010000000000000009, 4: -0.010000000000000009, 5: -0.010000000000000009, 6: -0.010000000000000009, 7: -0.010000000000000009, 9: -0.010000000000000009, 8: 0.010000000000000009}\n",
      "[[0.         0.0745098  0.1254902  0.41340782 0.89019608 1.\n",
      "  0.22766486 0.53297382 0.52419716 0.83072917]\n",
      " [0.         0.49411765 0.02745098 0.24581006 1.         0.74901961\n",
      "  0.05883126 0.92030251 0.55765122 0.67561521]\n",
      " [0.5027933  0.02745098 0.00392157 1.         1.         0.76862745\n",
      "  0.86589025 0.72584441 0.12050064 1.16627635]\n",
      " [0.         0.03529412 0.20784314 0.78212291 0.90980392 0.90980392\n",
      "  0.19654402 0.57874477 0.53708531 1.14539007]\n",
      " [0.         0.54117647 0.00392157 0.54748603 1.         0.56470588\n",
      "  0.20872404 0.88603746 0.2724855  0.98373984]\n",
      " [0.         0.         0.         0.67039106 0.8        0.48627451\n",
      "  0.13841418 0.49617284 0.17174935 1.00809717]\n",
      " [0.         0.50196078 0.00392157 0.57541899 1.         0.63529412\n",
      "  0.24966388 0.8795089  0.23825474 0.60548523]\n",
      " [0.         0.51372549 0.19607843 0.27374302 1.         0.82745098\n",
      "  0.1209069  0.80235789 0.49041033 0.96173469]\n",
      " [0.         0.         0.25490196 1.         0.45490196 1.\n",
      "  0.17391972 0.19154903 0.93392209 0.56144068]]\n",
      "-------------------------------------------------------\n",
      "6 ----------------------------------------------------\n",
      "{0: -0.009999999999999998, 8: -0.009999999999999998, 3: 0.0, 5: 0.0, 2: 0.020000000000000004, 4: 0.020000000000000004, 6: 0.020000000000000004, 7: 0.020000000000000004, 1: 0.03}\n",
      "[[0.         0.49411765 0.02745098 0.24581006 1.         0.74901961\n",
      "  0.05883126 0.92030251 0.55765122 0.67561521]\n",
      " [0.5027933  0.02745098 0.00392157 1.         1.         0.76862745\n",
      "  0.86589025 0.72584441 0.12050064 1.16627635]\n",
      " [0.         0.03529412 0.20784314 0.78212291 0.90980392 0.90980392\n",
      "  0.19654402 0.57874477 0.53708531 1.14539007]\n",
      " [0.         0.54117647 0.00392157 0.54748603 1.         0.56470588\n",
      "  0.20872404 0.88603746 0.2724855  0.98373984]\n",
      " [0.         0.         0.         0.67039106 0.8        0.48627451\n",
      "  0.13841418 0.49617284 0.17174935 1.00809717]\n",
      " [0.         0.50196078 0.00392157 0.57541899 1.         0.63529412\n",
      "  0.24966388 0.8795089  0.23825474 0.60548523]\n",
      " [0.         0.51372549 0.19607843 0.27374302 1.         0.82745098\n",
      "  0.1209069  0.80235789 0.49041033 0.96173469]\n",
      " [0.         0.         0.25490196 1.         0.45490196 1.\n",
      "  0.17391972 0.19154903 0.93392209 0.56144068]]\n",
      "-------------------------------------------------------\n",
      "7 ----------------------------------------------------\n",
      "{0: 0.0, 6: 0.0, 1: 0.010000000000000009, 2: 0.010000000000000009, 7: 0.020000000000000004, 3: 0.04000000000000001, 5: 0.04000000000000001, 4: 0.06}\n",
      "[[0.5027933  0.02745098 0.00392157 1.         1.         0.76862745\n",
      "  0.86589025 0.72584441 0.12050064 1.16627635]\n",
      " [0.         0.03529412 0.20784314 0.78212291 0.90980392 0.90980392\n",
      "  0.19654402 0.57874477 0.53708531 1.14539007]\n",
      " [0.         0.54117647 0.00392157 0.54748603 1.         0.56470588\n",
      "  0.20872404 0.88603746 0.2724855  0.98373984]\n",
      " [0.         0.         0.         0.67039106 0.8        0.48627451\n",
      "  0.13841418 0.49617284 0.17174935 1.00809717]\n",
      " [0.         0.50196078 0.00392157 0.57541899 1.         0.63529412\n",
      "  0.24966388 0.8795089  0.23825474 0.60548523]\n",
      " [0.         0.51372549 0.19607843 0.27374302 1.         0.82745098\n",
      "  0.1209069  0.80235789 0.49041033 0.96173469]\n",
      " [0.         0.         0.25490196 1.         0.45490196 1.\n",
      "  0.17391972 0.19154903 0.93392209 0.56144068]]\n",
      "-------------------------------------------------------\n",
      "8 ----------------------------------------------------\n",
      "{6: -0.010000000000000002, 0: 0.0, 1: 0.0, 3: 0.0, 2: 0.03, 4: 0.03, 5: 0.03}\n",
      "[[0.5027933  0.02745098 0.00392157 1.         1.         0.76862745\n",
      "  0.86589025 0.72584441 0.12050064 1.16627635]\n",
      " [0.         0.03529412 0.20784314 0.78212291 0.90980392 0.90980392\n",
      "  0.19654402 0.57874477 0.53708531 1.14539007]\n",
      " [0.         0.54117647 0.00392157 0.54748603 1.         0.56470588\n",
      "  0.20872404 0.88603746 0.2724855  0.98373984]\n",
      " [0.         0.         0.         0.67039106 0.8        0.48627451\n",
      "  0.13841418 0.49617284 0.17174935 1.00809717]\n",
      " [0.         0.50196078 0.00392157 0.57541899 1.         0.63529412\n",
      "  0.24966388 0.8795089  0.23825474 0.60548523]\n",
      " [0.         0.51372549 0.19607843 0.27374302 1.         0.82745098\n",
      "  0.1209069  0.80235789 0.49041033 0.96173469]]\n",
      "-------------------------------------------------------\n",
      "9 ----------------------------------------------------\n",
      "{2: -0.019999999999999997, 5: -0.019999999999999997, 4: 0.0, 0: 0.010000000000000009, 1: 0.010000000000000009, 3: 0.020000000000000004}\n",
      "[[0.5027933  0.02745098 0.00392157 1.         1.         0.76862745\n",
      "  0.86589025 0.72584441 0.12050064 1.16627635]\n",
      " [0.         0.03529412 0.20784314 0.78212291 0.90980392 0.90980392\n",
      "  0.19654402 0.57874477 0.53708531 1.14539007]\n",
      " [0.         0.         0.         0.67039106 0.8        0.48627451\n",
      "  0.13841418 0.49617284 0.17174935 1.00809717]\n",
      " [0.         0.50196078 0.00392157 0.57541899 1.         0.63529412\n",
      "  0.24966388 0.8795089  0.23825474 0.60548523]\n",
      " [0.         0.51372549 0.19607843 0.27374302 1.         0.82745098\n",
      "  0.1209069  0.80235789 0.49041033 0.96173469]]\n",
      "-------------------------------------------------------\n",
      "10 ----------------------------------------------------\n",
      "{1: 0.0, 3: 0.0, 0: 0.020000000000000004, 2: 0.020000000000000004, 4: 0.020000000000000004}\n",
      "[[0.5027933  0.02745098 0.00392157 1.         1.         0.76862745\n",
      "  0.86589025 0.72584441 0.12050064 1.16627635]\n",
      " [0.         0.         0.         0.67039106 0.8        0.48627451\n",
      "  0.13841418 0.49617284 0.17174935 1.00809717]\n",
      " [0.         0.50196078 0.00392157 0.57541899 1.         0.63529412\n",
      "  0.24966388 0.8795089  0.23825474 0.60548523]\n",
      " [0.         0.51372549 0.19607843 0.27374302 1.         0.82745098\n",
      "  0.1209069  0.80235789 0.49041033 0.96173469]]\n",
      "-------------------------------------------------------\n",
      "11 ----------------------------------------------------\n",
      "{0: 0.0, 1: 0.010000000000000002, 2: 0.010000000000000002, 3: 0.030000000000000006}\n",
      "[[0.         0.         0.         0.67039106 0.8        0.48627451\n",
      "  0.13841418 0.49617284 0.17174935 1.00809717]\n",
      " [0.         0.50196078 0.00392157 0.57541899 1.         0.63529412\n",
      "  0.24966388 0.8795089  0.23825474 0.60548523]\n",
      " [0.         0.51372549 0.19607843 0.27374302 1.         0.82745098\n",
      "  0.1209069  0.80235789 0.49041033 0.96173469]]\n",
      "-------------------------------------------------------\n",
      "12 ----------------------------------------------------\n",
      "{1: -0.009999999999999998, 0: 0.0, 2: 0.0}\n",
      "[[0.         0.         0.         0.67039106 0.8        0.48627451\n",
      "  0.13841418 0.49617284 0.17174935 1.00809717]\n",
      " [0.         0.51372549 0.19607843 0.27374302 1.         0.82745098\n",
      "  0.1209069  0.80235789 0.49041033 0.96173469]]\n",
      "-------------------------------------------------------\n",
      "13 ----------------------------------------------------\n",
      "{1: -0.039999999999999994, 0: 0.010000000000000009}\n",
      "[[0.         0.         0.         0.67039106 0.8        0.48627451\n",
      "  0.13841418 0.49617284 0.17174935 1.00809717]]\n",
      "-------------------------------------------------------\n",
      "14 ----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\_methods.py:184: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[300], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k_number):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     images_clusters_importance \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_clusters_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(images_clusters_importance[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m      5\u001b[0m     all_images_clusters_features_bak \u001b[38;5;241m=\u001b[39m remove_least_important_clusters(images_clusters_importance)\n",
      "Cell \u001b[1;32mIn[298], line 10\u001b[0m, in \u001b[0;36mcheck_clusters_importance\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m Effect_of_cluster_removal \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      9\u001b[0m classify_results \u001b[38;5;241m=\u001b[39m cal_classify_results(img, remove\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 10\u001b[0m classify_results_remove \u001b[38;5;241m=\u001b[39m \u001b[43mcal_classify_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m probs \u001b[38;5;241m=\u001b[39m cal_probs(classify_results)\n\u001b[0;32m     13\u001b[0m probs_remove \u001b[38;5;241m=\u001b[39m cal_probs(classify_results_remove)\n",
      "Cell \u001b[1;32mIn[294], line 7\u001b[0m, in \u001b[0;36mcal_classify_results\u001b[1;34m(img_num, remove)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m clstr_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k_number_bak):\n\u001b[0;32m      6\u001b[0m     histograms \u001b[38;5;241m=\u001b[39m calculate_mean_imgs_clstrs_except_index(index_\u001b[38;5;241m=\u001b[39m clstr_num, img_num \u001b[38;5;241m=\u001b[39m img_num, remove\u001b[38;5;241m=\u001b[39mremove)\n\u001b[1;32m----> 7\u001b[0m     rslt \u001b[38;5;241m=\u001b[39m \u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistograms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     classify_results\u001b[38;5;241m.\u001b[39mappend(rslt)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m classify_results\n",
      "Cell \u001b[1;32mIn[289], line 12\u001b[0m, in \u001b[0;36mclassify\u001b[1;34m(datapoints, labels)\u001b[0m\n\u001b[0;32m      8\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(datapoints, labels, test_size\u001b[38;5;241m=\u001b[39mtest_size, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     10\u001b[0m clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     16\u001b[0m y_prob_test \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n",
      "File \u001b[1;32mc:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 348\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mc:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[1;32m-> 1146\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    954\u001b[0m         )\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 957\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    965\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ewint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    170\u001b[0m     )\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "for i in range(k_number - 1):\n",
    "    print(i, \"----------------------------------------------------\")\n",
    "    images_clusters_importance = check_clusters_importance()\n",
    "    print(np.array(images_clusters_importance[0]))\n",
    "    all_images_clusters_features_bak = remove_least_important_clusters(images_clusters_importance)\n",
    "    print(np.array(all_images_clusters_features_bak[0]))\n",
    "    k_number_bak -= 1\n",
    "    print(\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now I should remove the least important cluster from `all_images_clusters_features` and again call `check_clusters_importance()` function.\n",
    "the problem is that we are removing the least important clusters just from test images. we can't do this on other images. what sould we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change I_KNOW"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "3mVvdAtI9ONL",
    "lBEBJMkk9Tsz",
    "UcQ9WDY59Zlb",
    "06xiqibEqHid",
    "aWfpqHU1qPh4"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
